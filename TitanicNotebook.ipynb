{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Using R to Build and Evaluate a Basic Decision Tree Model\n",
        "\n",
        "First, we need in import the various libraries we require for our analysis."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "library(rpart)\n",
        "library(rattle)\n",
        "library(rpart.plot)\n",
        "library(RColorBrewer)\n",
        "library(caret)\n",
        "library(repr)\n",
        "library(tidyverse)\n",
        "\n",
        "options(repr.plot.width=15, repr.plot.height=15)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Get the data from a csv file\n",
        "\n",
        "titanic <- read.csv(\"titanic.csv\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Examine Data\n",
        "\n",
        "You can print out the dataframe by running a codeblock with the dataframe name in it- in this case ```titanic```. You can also use the ```summary``` command to see various summary statistics."
      ],
      "metadata": {
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Examine dataframe\n",
        "\n",
        "titanic"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at your data is critical before you start doing any analysis. In this specific dataset, the \"Survived\" column indicates whether the individual survived (\"1') or prerished (\"0\"). So, \"1\" is the positive case."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "summary(titanic)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up Training and Testing Datasets\n",
        "\n",
        "Now we need to take our data and start organizing it for our modeling. Remember you have to train and evaluate your model, so the first step is splitting our data into training and testing(evaluating) dataframes."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "## 75% sample for training data\n",
        "sample_size <- floor(0.75 * nrow(titanic))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we want to be able to directly compare models, we need to make sure the random sampling is the same. We do this by setting a seed which is used to generate the random sample. Anyone who uses this same seed will get the same random sample."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "## Use seed to make models reproduceable\n",
        "set.seed(123)\n",
        "\n",
        "## Determine the row numbers to sample\n",
        "train_split <- sample(seq_len(nrow(titanic)), size = sample_size)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code block takes our original dataframe and separates it into training and testing datasets based on the sample size we set earlier."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "## Split the data into 75% training and 25% testing\n",
        "train <- titanic[train_split, ]\n",
        "test <- titanic[-train_split, ]\n",
        "\n",
        "## Validate that the dataframes are correct\n",
        "\n",
        "cat(\"There are \", nrow(train), \" rows in the training data. \\n\")\n",
        "cat(\"There are \", nrow(test), \" rows in the testing data.\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use the Training Dataset to Build the Model\n",
        "\n",
        "We are going to use the R library called rpart to create our decision tree. You can read more about it here: http://www.milbo.org/doc/prp.pdf\n",
        "\n",
        "In R, there is a standard way to create the model that uses an equation format similar to a standard linear equation. On the left is the predicted or dependent variable, ```~``` indicates the equal sign, and each independent variable is to the right of this sign.\n",
        "\n",
        "```R\n",
        "predicted_variable ~ independent_variable_1 + independent_variable_2\n",
        "```\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "## Build a decision tree model\n",
        "my_tree <- rpart(Survived ~ Pclass + Sex + Age + Siblings.Spouses.Aboard + Parents.Children.Aboard + Fare, data = train, method = \"class\", cp =.01)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot the Decision Tree"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "## Plot the model results\n",
        "rpart.plot(my_tree)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Examine the Rules from our Tree Model\n",
        "\n",
        "The ```rpart``` library also has a way to print out a table that defines all the rules for the generated model. After you run the code below, the table will give you the probability in the 'Survived\" column and the rules. This rules table represents the end nodes in the model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "rpart.rules(my_tree, cover=TRUE)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate the Model\n",
        "\n",
        "Finally, we need to evaluate how well our model performed using the testing data (we can also call this the holdout data). Do do this we use our model to predict the test data outcomes. Given we already know the outcomes, we compare the predictions to the actual outcomes. We use the confusion matrix to graphically represent the different types of errors our model may have."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "## Create the probabilities for each test data point\n",
        "predict_probs <- as.data.frame(predict(my_tree, newdata = test, type = \"p\"))\n",
        "\n",
        "## Create the predicted test values and ground truth values and .5 threshold value\n",
        "predicted <- as.integer(predict_probs$`1` > .5)\n",
        "actual <- test$Survived\n",
        "\n",
        "## Build confusion matrix\n",
        "confusionMatrix(as.factor(predicted), as.factor(actual), positive = \"1\")\n",
        "\n",
        "## https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "trusted": false
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R",
      "codemirror_mode": "r",
      "pygments_lexer": "r",
      "mimetype": "text/x-r-source",
      "file_extension": ".r",
      "version": "4.1.3"
    },
    "nteract": {
      "version": "nteract-on-jupyter@2.1.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}